# Markov Chain Simulation

A python simulation of a simple markov chain, an MDP, and a POMDP problem. The Markov chain takes as input a transition probability matrix, while the MDP/POMDP takes states, actions, probabilities matrices, observations (if applicable), and cost function, all corresponding to Numpy objects.

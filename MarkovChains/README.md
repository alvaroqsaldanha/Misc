# Markov Chain Simulation

A python simulation of a simple markov chain and an MDP problem. The Markov chain takes as input a transition probability matrix, while the MDP takes states, actions, probabilities matrixes, and cost function, all corresponding to Numpy objects.
